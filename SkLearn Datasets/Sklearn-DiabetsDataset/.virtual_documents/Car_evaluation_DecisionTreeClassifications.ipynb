


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score, confusion_matrix, classification_report





df= pd.read_csv('E:/Python Projects/shohreh/Shohreh_GitHub_Repository/Data-Analysis-And-Machine-Learning-Projects/3. Business Intelligence and Sales Analysis/Car_evaluation/car_evaluation.csv', header= None)


df.info()


df.head()











# change columns name with appropriate name
# df= df.rename(columns={0: 'buying', 1: 'maint', 2: 'doors', 3: 'persons', 4: 'lug_boot', 5: 'safety', 6: 'class'})
df.columns= ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']


df.columns


pd.DataFrame(df.nunique(), columns=['Number of unique values'])


def valuecounts(df, column):
    return pd.DataFrame(df[column].value_counts(), columns=['count'])


for col in df.columns:
    print(valuecounts(df, col))
    print(15*'*')


valuecounts(df,'buying')


encoders = {}
for col in df.columns:
    if df[col].dtype == 'object':
        le= LabelEncoder()
        df[col] = le.fit_transform(df[col])
        encoders[col] = le





X= df.drop(['class'], axis=1)
y=df['class']
#X.shape, y.shape
X_train, X_test, y_train, y_test= train_test_split(X, y, train_size= 0.7, random_state= 42)


# # standardization
# scaler= StandardScaler()
# X_train= scaler.fit_transform(X_train)
# X_test= scaler.transform(X_test)


# Normalization
scaler= MinMaxScaler()
X_train= scaler.fit_transform(X_train)
X_test= scaler.transform(X_test)





model= DecisionTreeClassifier()
model.fit(X_train, y_train)
y_pred= model.predict(X_test)
print(f'Confusion Matrix: {confusion_matrix(y_test, y_pred)}')
print(f'f1_score: {f1_score(y_test, y_pred, average= "micro")}')
print(f'Classifiction_report: {classification_report(y_test, y_pred, target_names= encoders["class"].classes_)}')






model= DecisionTreeClassifier()
param_distribution= {
    'criterion': ['gini', 'entropy'],
    'splitter': ['best', 'random'],
    'max_depth': [None, 3, 5, 10],
    'min_samples_split': [2, 5, 10 , 20],
    'min_samples_leaf': [1, 5, 10, 20],
    'max_features': [None, "sqrt", "log2", 0.5, 'auto'],
    'random_state' : [None, 42],
    'max_leaf_nodes': [None, 10, 50],
    'class_weight' : [None, "balanced"]
    
}
random_search= RandomizedSearchCV(model, param_distribution, n_iter= 100, cv= 5, random_state= 42,scoring='accuracy', n_jobs=-1)
random_search.fit(X_train, y_train)
print(random_search.best_params_)


model= DecisionTreeClassifier(splitter= 'random',
                            random_state= 42,
                            min_samples_split= 2,
                            min_samples_leaf= 1,
                            max_leaf_nodes= None,
                            max_features= None,
                            max_depth= None,
                            criterion= 'entropy',
                            class_weight= None)
model.fit(X_train, y_train)
y_pred= model.predict(X_test)
print(f'Confusion Matrix: {confusion_matrix(y_test, y_pred)}')
print(f'f1_score: {f1_score(y_test, y_pred, average= "micro")}')
print(f'Classifiction_report: {classification_report(y_test, y_pred, target_names= encoders["class"].classes_)}')





model= RandomForestClassifier()
model.fit(X_train, y_train)
y_pred= model.predict(X_test)
print(f'Confusion Matrix: {confusion_matrix(y_test, y_pred)}')
print(f'f1_score: {f1_score(y_test, y_pred, average= "micro")}')
print(f'Classifiction_report: {classification_report(y_test, y_pred, target_names= encoders["class"].classes_)}')





model= RandomForestClassifier()
params={
     'n_estimators': [10, 100, 200],
    'max_depth': [None, 5, 10],
    'min_samples_split': [2, 5, 10, 20],
    'min_samples_leaf': [1, 5, 10, 20],
    'max_features': [None, "sqrt", "log2", 0.5, 'auto'],
    'bootstrap': [True, False],
    'random_state': [42, None],
    'n_jobs': [-1, None],
    'class_weight': [None, "balanced"],
    'oob_score': [True, False]  
}
random_search = RandomizedSearchCV(model, params, n_iter=100, cv= 5, n_jobs= -1,random_state= 42, scoring='accuracy')
random_search.fit(X_train, y_train)
print(f'dest_parameters: {random_search.best_params_}')
print(f'dest_parameters: {random_search.best_params_}')


model= RandomForestClassifier(
n_estimators=100,           # More trees
    max_depth=None,              # Limit tree depth
    min_samples_split=2,       # Require more samples to split
    min_samples_leaf=1,        # Require more samples at leaf
    max_features= 0.5,       # Feature sampling
    bootstrap=False,            # Bootstrap sampling
    random_state=42,           # Reproducibility
    n_jobs=None,                 # Use all cores
    class_weight='balanced',   # Handle imbalanced classes
    oob_score=False            # Out-of-bag scoring
)
model.fit(X_train, y_train)
y_pred= model.predict(X_test)
print(f'Confusion Matrix: {confusion_matrix(y_test, y_pred)}')
print(f'f1_score: {f1_score(y_test, y_pred, average= "micro")}')
print(f'Classifiction_report: {classification_report(y_test, y_pred, target_names= encoders["class"].classes_)}')



